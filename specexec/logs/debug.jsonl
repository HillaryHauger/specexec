{"msg_type": "config", "gen_type": "SpecExecBase", "model_0": "meta-llama/Llama-2-7b-chat-hf", "model_1": "meta-llama/Llama-2-70b-chat-hf", "temperature": 0.6, "max_n_beams": "10", "max_beam_len": "32", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "100", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-03-11 11:07:15", "date": "250311", "hostname": "mdsi-gpu02", "commit": "none", "offload": true, "device": "A100-PCIE-40GB", "device_size": 2}
{"msg_type": "summary", "run": 0, "max_n_beams": 10, "max_beam_len": 32, "branching": null, "max_budget": 100, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "meta-llama/Llama-2-7b-chat-hf", "target_model_name": "meta-llama/Llama-2-70b-chat-hf", "prompt_len": 146, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 4, "tree_size": 100, "t0": 1.65, "t1": 5.28, "tft": 9.3185, "input_0": 314, "input_1": 101, "min_CLP": -4.2, "draft_iters": 32.0, "mem_use": 30.02, "gen_rate": 33.0, "speed": 4.76, "text": " A Dyson Sphere is a hypothetica"}
{"msg_type": "summary", "run": 1, "max_n_beams": 10, "max_beam_len": 32, "branching": null, "max_budget": 100, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "meta-llama/Llama-2-7b-chat-hf", "target_model_name": "meta-llama/Llama-2-70b-chat-hf", "prompt_len": 436, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 22.4, "tree_w": 14, "tree_size": 100, "t0": 1.284, "t1": 5.238, "tft": 7.3355, "input_0": 310, "input_1": 101, "min_CLP": -4.61, "draft_iters": 23.2, "mem_use": 30.84, "gen_rate": 7.6, "speed": 1.16, "text": "\\nI apologize for the mistake in"}
{"msg_type": "summary", "run": 2, "max_n_beams": 10, "max_beam_len": 32, "branching": null, "max_budget": 100, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "meta-llama/Llama-2-7b-chat-hf", "target_model_name": "meta-llama/Llama-2-70b-chat-hf", "prompt_len": 597, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 28.5, "tree_w": 7, "tree_size": 100, "t0": 1.61, "t1": 5.235, "tft": 7.1516, "input_0": 388, "input_1": 101, "min_CLP": -4.21, "draft_iters": 29.0, "mem_use": 31.17, "gen_rate": 17.5, "speed": 2.56, "text": " Sure, I can help you with that!"}
{"msg_type": "summary", "run": 3, "max_n_beams": 10, "max_beam_len": 32, "branching": null, "max_budget": 100, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "meta-llama/Llama-2-7b-chat-hf", "target_model_name": "meta-llama/Llama-2-70b-chat-hf", "prompt_len": 181, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 62, "tree_h": 28.2, "tree_w": 8, "tree_size": 100, "t0": 1.6, "t1": 5.255, "tft": 6.4106, "input_0": 452, "input_1": 101, "min_CLP": -4.37, "draft_iters": 28.8, "mem_use": 30.26, "gen_rate": 15.5, "speed": 2.26, "text": "\\n Sure, here is a Python script"}
{"msg_type": "summary", "run": 4, "max_n_beams": 10, "max_beam_len": 32, "branching": null, "max_budget": 100, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "meta-llama/Llama-2-7b-chat-hf", "target_model_name": "meta-llama/Llama-2-70b-chat-hf", "prompt_len": 148, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 32.0, "tree_w": 7, "tree_size": 100, "t0": 1.7067, "t1": 5.25, "tft": 7.0577, "input_0": 468, "input_1": 101, "min_CLP": -4.16, "draft_iters": 32.0, "mem_use": 30.2, "gen_rate": 14.0, "speed": 2.01, "text": "\"\\nOf course, I'd be happy to he"}
{"msg_type": "summary", "run": 5, "max_n_beams": 10, "max_beam_len": 32, "branching": null, "max_budget": 100, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "meta-llama/Llama-2-7b-chat-hf", "target_model_name": "meta-llama/Llama-2-70b-chat-hf", "prompt_len": 632, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 27.0, "tree_w": 7, "tree_size": 100, "t0": 1.564, "t1": 5.264, "tft": 7.4982, "input_0": 393, "input_1": 101, "min_CLP": -3.87, "draft_iters": 27.8, "mem_use": 31.29, "gen_rate": 6.4, "speed": 0.94, "text": " Sure, here\\'s a bullet list for"}
{"msg_type": "summary", "run": 6, "max_n_beams": 10, "max_beam_len": 32, "branching": null, "max_budget": 100, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "meta-llama/Llama-2-7b-chat-hf", "target_model_name": "meta-llama/Llama-2-70b-chat-hf", "prompt_len": 728, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 27.3, "tree_w": 7, "tree_size": 100, "t0": 1.5333, "t1": 5.25, "tft": 7.4609, "input_0": 375, "input_1": 101, "min_CLP": -4.15, "draft_iters": 27.7, "mem_use": 31.5, "gen_rate": 10.7, "speed": 1.57, "text": " There are several alternatives "}
{"msg_type": "summary", "run": 7, "max_n_beams": 10, "max_beam_len": 32, "branching": null, "max_budget": 100, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "meta-llama/Llama-2-7b-chat-hf", "target_model_name": "meta-llama/Llama-2-70b-chat-hf", "prompt_len": 1206, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 28.7, "tree_w": 7, "tree_size": 100, "t0": 1.7256, "t1": 5.2522, "tft": 8.1226, "input_0": 387, "input_1": 101, "min_CLP": -4.1, "draft_iters": 29.3, "mem_use": 32.6, "gen_rate": 4.0, "speed": 0.57, "text": "\" Sure, I'd be happy to help wit"}
{"msg_type": "summary", "run": 8, "max_n_beams": 10, "max_beam_len": 32, "branching": null, "max_budget": 100, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "meta-llama/Llama-2-7b-chat-hf", "target_model_name": "meta-llama/Llama-2-70b-chat-hf", "prompt_len": 699, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 24.2, "tree_w": 8, "tree_size": 100, "t0": 1.3775, "t1": 5.235, "tft": 7.1679, "input_0": 361, "input_1": 101, "min_CLP": -4.09, "draft_iters": 25.2, "mem_use": 31.42, "gen_rate": 9.2, "speed": 1.4, "text": "\" Sure, here's a list of the leg"}
{"msg_type": "summary", "run": 9, "max_n_beams": 10, "max_beam_len": 32, "branching": null, "max_budget": 100, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "meta-llama/Llama-2-7b-chat-hf", "target_model_name": "meta-llama/Llama-2-70b-chat-hf", "prompt_len": 562, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 29.5, "tree_w": 8, "tree_size": 100, "t0": 1.645, "t1": 5.235, "tft": 6.9853, "input_0": 393, "input_1": 101, "min_CLP": -5.16, "draft_iters": 30.0, "mem_use": 31.1, "gen_rate": 21.5, "speed": 3.12, "text": "There are many beginner-friendly"}
{"msg_type": "exp", "max_n_beams": 10, "max_beam_len": 32, "min_log_prob": null, "max_budget": 100, "max_branch_width": 32, "gen_rate": 13.94, "gen_rate_micro": 10.26, "gen_speed": 2.035, "gen_speed_micro": 1.503, "t0": 1.5696, "t1": 5.2494, "input_0": 384.1, "input_1": 101.0, "tree_size": 100.0, "tree_w": 7.7, "tree_h": 28.0, "prompt_len": 533.5, "min_CLP": -4.29, "mem_use": 32.6, "exp_time": 340.02}
