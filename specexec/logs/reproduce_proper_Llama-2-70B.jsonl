{"msg_type": "config", "gen_type": "SpecExecBase", "model_0": "meta-llama/Llama-2-7b-chat-hf", "model_1": "meta-llama/Llama-2-70b-chat-hf", "temperature": 0.6, "max_n_beams": "10", "max_beam_len": "32", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "2048", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-03-11 11:22:31", "date": "250311", "hostname": "gpu15", "commit": "none", "offload": true, "device": "L40S", "device_size": 2}
{"msg_type": "config", "gen_type": "SpecExecBase", "model_0": "meta-llama/Llama-2-7b-chat-hf", "model_1": "meta-llama/Llama-2-70b-chat-hf", "temperature": 0.6, "max_n_beams": "10", "max_beam_len": "32", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "1024", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-03-11 11:36:46", "date": "250311", "hostname": "mdsi-gpu02", "commit": "none", "offload": true, "device": "A100-PCIE-40GB", "device_size": 2}
{"msg_type": "config", "gen_type": "SpecExecBase", "model_0": "meta-llama/Llama-2-7b-chat-hf", "model_1": "meta-llama/Llama-2-70b-chat-hf", "temperature": 0.6, "max_n_beams": "", "max_beam_len": "32", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "1024", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-03-11 13:33:40", "date": "250311", "hostname": "mdsi-gpu02", "commit": "none", "offload": true, "device": "A100-PCIE-40GB", "device_size": 2}
